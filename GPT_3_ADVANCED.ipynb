{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZoGEdxvr/WZ9kCb7n0w66",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MUTHUKRISHNAN123/MACHINE-LEARNING-/blob/main/GPT_3_ADVANCED.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "“GPT-3 (Generative Pre-trained Transformer 3) is a highly advanced language model trained on a very large corpus of text. In spite of its internal complexity, it is surprisingly simple to operate: you feed it some text, and the model generates some more, following a similar style and structure.”\n",
        "\n",
        "“GPT-3 is non-deterministic, in the sense that given the same input, multiple runs of the engine will return different responses.”\n"
      ],
      "metadata": {
        "id": "4CYkY0FW2ZNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENGINE:\n",
        "OpenAI has four engines to choose from. This is definitely the black box part of GPT3. I have read that Davinci is the most “advanced and capable” so we will stick with it per recommendations across the interwebs."
      ],
      "metadata": {
        "id": "3_VNev552g0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESPONSE LENGTH:\n",
        "Controls how much text is generated. Think character count here for all you Microsoft Word or Google Doc users. If we set it at 150 that means that GPT-3 will add 150 tokens to the text. A token is defined as a word or a punctuation mark."
      ],
      "metadata": {
        "id": "llcBG4Ni2wVb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEMPERATURE:\n",
        "This setting controls the randomness of the generated text. The higher the temperature the crazier what gets spit out. A value of 0 makes the engine deterministic, which means that it will always generate the same output for a given input. A value of 1 makes the engine take the most risks aka makes it the most creative."
      ],
      "metadata": {
        "id": "0s6qooxl3CzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOP P:\n",
        "\n",
        "This parameter also has some control over the randomness and creativity of the text generated by GPT3. For some reason it is used less than the Temperature. The OpenAI documentation recommends that only one of Temperature and Top P are used, so when using one of them, make sure that the other is set to 1."
      ],
      "metadata": {
        "id": "3ZYpa6hm3PP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FREQUENCY PENALTY:\n",
        "Frequency penalty works by lowering the chances of a word being selected again the more times that word has already been used."
      ],
      "metadata": {
        "id": "GNZeqNNT3kvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRESENCE PENALTY:\n",
        "Frequency penalty works by lowering the chances of a word being selected again the more times that word has already been used."
      ],
      "metadata": {
        "id": "epgIdP083-6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "“the difference between these two options is subtle, but you can think of Frequency Penalty as a way to prevent word repetitions, and Presence Penalty as a way to prevent topic repetitions.”"
      ],
      "metadata": {
        "id": "_4TOfQcD4Kyi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BEST OF:\n",
        "can be used to have GPT-3 generate multiple responses to a query. The Playground then selects the best one and displays it. Recommend going with defaults here."
      ],
      "metadata": {
        "id": "c8bmLJMY4UOA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STOP SEQUENCE:\n",
        " helps to prevent GPT3 from cutting off mid-sentence if it runs up against the max length permitted by the response length parameter. The stop sequence basically forces GPT3 to stop at a certain point. The returned text will not contain the stop sequence. "
      ],
      "metadata": {
        "id": "5vwpFIHz4b1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "START TEXT:\n",
        "Text to automatically append after the user’s input. This will happen before sending a request to GPT3 which will come in handy when we are building our bot."
      ],
      "metadata": {
        "id": "gysVKjQB5SMg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESTART TEXT:\n",
        "Text to append after the models generation to continue the patterned structure. In other words, the restart text helps so you don’t need to type the prefix."
      ],
      "metadata": {
        "id": "DjAwBMUN5UJc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nQCt4gWl5oA4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n-A0edoo6lSv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}